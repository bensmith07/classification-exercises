{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f2d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn as sk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from env import get_db_url, user, password, host\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "\n",
    "# pandas display preferences\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.precision', 3)\n",
    "#pd.option_context('display.max_rows', None)\n",
    "\n",
    "line_break = ('-' * 50)\n",
    "line_break_2 = ('\\n' + '=' * 50 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3adad",
   "metadata": {},
   "source": [
    "# Titanic Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f874cf9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "    Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "    Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "    Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "    What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cda716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df = prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7890b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'survived'\n",
    "positive = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b406a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t n = 498\n",
      "test\t n = 179\n",
      "validate n = 214\n"
     ]
    }
   ],
   "source": [
    "train, test, validate = prepare.train_test_validate_split(df, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cdfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "x_validate = validate.drop(columns=target)\n",
    "y_validate = validate[target]\n",
    "\n",
    "x_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf2c3a",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dbf6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42, min_samples_leaf=1, max_depth=10)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f13a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame()\n",
    "train_results['actual'] = train[target]\n",
    "train_results['baseline'] = train[target].mode()[0]\n",
    "train_results['predicted'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf3d23",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d8efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f951b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.93\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[299   8]\n",
      " [ 27 164]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.917    0.953      0.93      0.935         0.931\n",
      "recall       0.974    0.859      0.93      0.916         0.930\n",
      "f1-score     0.945    0.904      0.93      0.924         0.929\n",
      "support    307.000  191.000      0.93    498.000       498.000\n"
     ]
    }
   ],
   "source": [
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_train, y_pred))\n",
    "print(line_break)\n",
    "print('Classification Report: \\n', class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20100f",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2964aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.86\n",
      "F1 Score: 0.90\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(x_train, y_train)\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "support_1 = int(y_train[y_train == 1].count())\n",
    "support_0 = int(y_train[y_train == 0].count())\n",
    "\n",
    "n=len(train)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual != positive)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual != positive)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual == positive)]) / n\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1_score:.2f}')\n",
    "print(f'Support 1: {support_1}')\n",
    "print(f'Support 0: {support_0}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382028ef",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5ffbdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR MIN_SAMPLES_LEAF = 1\n",
      "AND MAX_DEPTH = 10\n",
      "\n",
      "Model Score: 0.93\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[299   8]\n",
      " [ 27 164]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.917    0.953      0.93      0.935         0.931\n",
      "recall       0.974    0.859      0.93      0.916         0.930\n",
      "f1-score     0.945    0.904      0.93      0.924         0.929\n",
      "support    307.000  191.000      0.93    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.93\n",
      "Precision: 0.95\n",
      "Recall: 0.86\n",
      "F1 Score: 0.90\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 2\n",
      "AND MAX_DEPTH = 9\n",
      "\n",
      "Model Score: 0.88\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[293  14]\n",
      " [ 45 146]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.867    0.912     0.882      0.890         0.884\n",
      "recall       0.954    0.764     0.882      0.859         0.882\n",
      "f1-score     0.909    0.832     0.882      0.870         0.879\n",
      "support    307.000  191.000     0.882    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.88\n",
      "Precision: 0.91\n",
      "Recall: 0.76\n",
      "F1 Score: 0.83\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 3\n",
      "AND MAX_DEPTH = 8\n",
      "\n",
      "Model Score: 0.87\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[290  17]\n",
      " [ 50 141]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.853    0.892     0.865      0.873         0.868\n",
      "recall       0.945    0.738     0.865      0.841         0.865\n",
      "f1-score     0.896    0.808     0.865      0.852         0.863\n",
      "support    307.000  191.000     0.865    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.87\n",
      "Precision: 0.89\n",
      "Recall: 0.74\n",
      "F1 Score: 0.81\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 4\n",
      "AND MAX_DEPTH = 7\n",
      "\n",
      "Model Score: 0.86\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[289  18]\n",
      " [ 50 141]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.853    0.887     0.863       0.87         0.866\n",
      "recall       0.941    0.738     0.863       0.84         0.863\n",
      "f1-score     0.895    0.806     0.863       0.85         0.861\n",
      "support    307.000  191.000     0.863     498.00       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.86\n",
      "Precision: 0.89\n",
      "Recall: 0.74\n",
      "F1 Score: 0.81\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 5\n",
      "AND MAX_DEPTH = 6\n",
      "\n",
      "Model Score: 0.85\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[283  24]\n",
      " [ 50 141]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.850    0.855     0.851      0.852         0.852\n",
      "recall       0.922    0.738     0.851      0.830         0.851\n",
      "f1-score     0.884    0.792     0.851      0.838         0.849\n",
      "support    307.000  191.000     0.851    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.85\n",
      "Precision: 0.85\n",
      "Recall: 0.74\n",
      "F1 Score: 0.79\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 6\n",
      "AND MAX_DEPTH = 5\n",
      "\n",
      "Model Score: 0.83\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[281  26]\n",
      " [ 57 134]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.831    0.838     0.833      0.834         0.834\n",
      "recall       0.915    0.702     0.833      0.808         0.833\n",
      "f1-score     0.871    0.764     0.833      0.817         0.830\n",
      "support    307.000  191.000     0.833    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.83\n",
      "Precision: 0.84\n",
      "Recall: 0.70\n",
      "F1 Score: 0.76\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 7\n",
      "AND MAX_DEPTH = 4\n",
      "\n",
      "Model Score: 0.82\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[274  33]\n",
      " [ 56 135]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.830    0.804     0.821      0.817         0.820\n",
      "recall       0.893    0.707     0.821      0.800         0.821\n",
      "f1-score     0.860    0.752     0.821      0.806         0.819\n",
      "support    307.000  191.000     0.821    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.82\n",
      "Precision: 0.80\n",
      "Recall: 0.71\n",
      "F1 Score: 0.75\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 8\n",
      "AND MAX_DEPTH = 3\n",
      "\n",
      "Model Score: 0.82\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[279  28]\n",
      " [ 63 128]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.816    0.821     0.817      0.818         0.818\n",
      "recall       0.909    0.670     0.817      0.789         0.817\n",
      "f1-score     0.860    0.738     0.817      0.799         0.813\n",
      "support    307.000  191.000     0.817    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.82\n",
      "Precision: 0.82\n",
      "Recall: 0.67\n",
      "F1 Score: 0.74\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 9\n",
      "AND MAX_DEPTH = 2\n",
      "\n",
      "Model Score: 0.80\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[275  32]\n",
      " [ 67 124]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.804    0.795     0.801      0.799         0.801\n",
      "recall       0.896    0.649     0.801      0.772         0.801\n",
      "f1-score     0.847    0.715     0.801      0.781         0.797\n",
      "support    307.000  191.000     0.801    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.80\n",
      "Precision: 0.79\n",
      "Recall: 0.65\n",
      "F1 Score: 0.71\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n",
      "FOR MIN_SAMPLES_LEAF = 10\n",
      "AND MAX_DEPTH = 1\n",
      "\n",
      "Model Score: 0.74\n",
      "--------------------------------------------------\n",
      "Confusion Matrix: \n",
      " [[304   3]\n",
      " [125  66]]\n",
      "--------------------------------------------------\n",
      "Classification Report: \n",
      "                  0        1  accuracy  macro avg  weighted avg\n",
      "precision    0.709    0.957     0.743      0.833         0.804\n",
      "recall       0.990    0.346     0.743      0.668         0.743\n",
      "f1-score     0.826    0.508     0.743      0.667         0.704\n",
      "support    307.000  191.000     0.743    498.000       498.000\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.74\n",
      "Precision: 0.96\n",
      "Recall: 0.35\n",
      "F1 Score: 0.51\n",
      "Support 1: 191\n",
      "Support 0: 307\n",
      "\n",
      "True Postive Rate:\t0.33\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.60\n",
      "False Negative Rate:\t0.05\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf = 1\n",
    "max_depth = 10\n",
    "\n",
    "for i in range(1, 11):\n",
    "    \n",
    "    print(f'FOR MIN_SAMPLES_LEAF = {min_samples_leaf}\\nAND MAX_DEPTH = {max_depth}')\n",
    "    print()\n",
    "\n",
    "    # 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "    clf = RandomForestClassifier(random_state=42, \n",
    "                                 min_samples_leaf=min_samples_leaf, \n",
    "                                 max_depth=max_depth)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    \n",
    "    # 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "    print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "    print(line_break)\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_train, y_pred))\n",
    "    print(line_break)\n",
    "    print('Classification Report: \\n', pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)))\n",
    "    print(line_break)\n",
    "    \n",
    "    # 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "    accuracy = clf.score(x_train, y_train)\n",
    "    precision = sk.metrics.precision_score(y_train, y_pred, pos_label=positive)\n",
    "    recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "    f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "    support_1 = int(y_train[y_train == 1].count())\n",
    "    support_0 = int(y_train[y_train == 0].count())\n",
    "\n",
    "    n=len(train)\n",
    "    tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "    fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual != positive)]) / n\n",
    "    tn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual != positive)]) / n\n",
    "    fn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual == positive)]) / n\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1_score:.2f}')\n",
    "    print(f'Support 1: {support_1}')\n",
    "    print(f'Support 0: {support_0}')\n",
    "    print()\n",
    "    print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "    print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "    print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "    print(f'False Negative Rate:\\t{fn_rate:.2f}')\n",
    "    \n",
    "    \n",
    "    print(line_break_2)\n",
    "    \n",
    "    min_samples_leaf += 1\n",
    "    max_depth -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ba3a9",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac19ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe to store model results\n",
    "model_results = pd.DataFrame(columns=['model_number', 'metric_type', 'sample_type', 'score'])\n",
    "\n",
    "# empty dataframe to store information about the model itself\n",
    "model_info = pd.DataFrame(columns=['model_number', 'min_samples_leaf', 'max_depth'])\n",
    "######################################################################################\n",
    "# store baseline metrics\n",
    "\n",
    "model_number = 'baseline'\n",
    "\n",
    "# store info about the model\n",
    "dct = {'model_number': model_number,\n",
    "       'min_samples_leaf': np.nan,\n",
    "       'max_depth': np.nan}\n",
    "model_info = model_info.append(dct, ignore_index=True)\n",
    "\n",
    "# establish baseline predictions for train sample\n",
    "y_pred = baseline_pred = pd.Series([train[target].mode()[0]]).repeat(len(train))\n",
    "\n",
    "# get metrics\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'train', \n",
    "       'metric_type': 'accuracy',\n",
    "       'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'train', \n",
    "       'metric_type': 'precision',\n",
    "       'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'train', \n",
    "       'metric_type': 'recall',\n",
    "       'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'train', \n",
    "       'metric_type': 'f1_score',\n",
    "       'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "# establish baseline predictions for validate sample\n",
    "y_pred = baseline_pred = pd.Series([train[target].mode()[0]]).repeat(len(validate))\n",
    "\n",
    "# get metrics\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'validate', \n",
    "       'metric_type': 'f1_score',\n",
    "       'score': sk.metrics.f1_score(y_validate, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'validate', \n",
    "       'metric_type': 'accuracy',\n",
    "       'score': sk.metrics.accuracy_score(y_validate, y_pred)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'validate', \n",
    "       'metric_type': 'precision',\n",
    "       'score': sk.metrics.precision_score(y_validate, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "dct = {'model_number': model_number, \n",
    "       'sample_type': 'validate', \n",
    "       'metric_type': 'recall',\n",
    "       'score': sk.metrics.recall_score(y_validate, y_pred, pos_label=positive)}\n",
    "model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "# create models\n",
    "\n",
    "model_number = 1\n",
    "max_depth = 10\n",
    "min_samples_leaf = 1\n",
    "\n",
    "for i in range(1, 11):\n",
    "    \n",
    "    # store info about the model\n",
    "    dct = {'model_number': model_number,\n",
    "           'min_samples_leaf': min_samples_leaf,\n",
    "           'max_depth': max_depth}\n",
    "    model_info = model_info.append(dct, ignore_index=True)\n",
    "    \n",
    "    # fit the classifier to the training sample and transform\n",
    "    clf = RandomForestClassifier(random_state=42, \n",
    "                                     min_samples_leaf=min_samples_leaf, \n",
    "                                     max_depth=max_depth)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    \n",
    "\n",
    "    # results for train sample\n",
    "    y_pred = clf.predict(x_train)\n",
    "    \n",
    "    \n",
    "    # get metrics\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_train, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'train', \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_train, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "\n",
    "    # results for validate sample\n",
    "    y_pred = clf.predict(x_validate)\n",
    "    \n",
    "    # get metrics\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'f1_score',\n",
    "           'score': sk.metrics.f1_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'accuracy',\n",
    "           'score': sk.metrics.accuracy_score(y_validate, y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'precision',\n",
    "           'score': sk.metrics.precision_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "    dct = {'model_number': model_number, \n",
    "           'sample_type': 'validate', \n",
    "           'metric_type': 'recall',\n",
    "           'score': sk.metrics.recall_score(y_validate, y_pred, pos_label=positive)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "    \n",
    "    model_number += 1\n",
    "    min_samples_leaf += 1\n",
    "    max_depth -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aeacc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_results():\n",
    "    return model_results.pivot_table(columns='model_number', \n",
    "                                     index=('metric_type', 'sample_type'), \n",
    "                                     values='score',\n",
    "                                     aggfunc=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c40ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_number min_samples_leaf max_depth\n",
       "0      baseline              NaN       NaN\n",
       "1             1                1        10\n",
       "2             2                2         9\n",
       "3             3                3         8\n",
       "4             4                4         7\n",
       "5             5                5         6\n",
       "6             6                6         5\n",
       "7             7                7         4\n",
       "8             8                8         3\n",
       "9             9                9         2\n",
       "10           10               10         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f2c719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_type</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.801</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric_type  accuracy          f1_score          precision          recall  \\\n",
       "sample_type     train validate    train validate     train validate  train   \n",
       "model_number                                                                 \n",
       "1               0.930    0.804    0.904    0.716     0.953    0.803  0.859   \n",
       "2               0.882    0.818    0.832    0.738     0.912    0.821  0.764   \n",
       "3               0.865    0.818    0.808    0.742     0.892    0.812  0.738   \n",
       "4               0.863    0.813    0.806    0.730     0.887    0.818  0.738   \n",
       "5               0.851    0.818    0.792    0.742     0.855    0.812  0.738   \n",
       "6               0.833    0.818    0.764    0.735     0.838    0.831  0.702   \n",
       "7               0.821    0.808    0.752    0.732     0.804    0.789  0.707   \n",
       "8               0.817    0.822    0.738    0.743     0.821    0.833  0.670   \n",
       "9               0.801    0.808    0.715    0.725     0.795    0.806  0.649   \n",
       "10              0.743    0.729    0.508    0.482     0.957    0.900  0.346   \n",
       "baseline        0.616    0.617    0.000    0.000     0.000    0.000  0.000   \n",
       "\n",
       "metric_type            \n",
       "sample_type  validate  \n",
       "model_number           \n",
       "1               0.646  \n",
       "2               0.671  \n",
       "3               0.683  \n",
       "4               0.659  \n",
       "5               0.683  \n",
       "6               0.659  \n",
       "7               0.683  \n",
       "8               0.671  \n",
       "9               0.659  \n",
       "10              0.329  \n",
       "baseline        0.000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model_results().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391c3d5",
   "metadata": {},
   "source": [
    "Accuracy tends to be the highest metric across the models, followed by precision, then recall. \n",
    "Model 1 performs best on the in-sample data, most likely due to it's large max depth_value of 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c16371",
   "metadata": {},
   "source": [
    "### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74408f6f",
   "metadata": {},
   "source": [
    "Model 8 - with min_samples_leaf = 8 and max_depth = 3 - performs best across all metrics (i.e. has less dropoff in performance between train and validate sets. )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

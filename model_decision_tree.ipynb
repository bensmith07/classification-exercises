{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb03cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn as sk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from env import get_db_url, user, password, host\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "\n",
    "# pandas display preferences\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.precision', 3)\n",
    "#pd.option_context('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490be151",
   "metadata": {},
   "source": [
    "# Titanic - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90442507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad5e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fab03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=42, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=42, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e40edda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62977358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0965ece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a343b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'survived'\n",
    "\n",
    "x_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "x_validate = validate.drop(columns=target)\n",
    "y_validate = validate[target]\n",
    "\n",
    "x_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726a986",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e412fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "779       1         0\n",
       "159       0         0\n",
       "738       0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'survived'\n",
    "\n",
    "train_results = pd.DataFrame()\n",
    "train_results['actual'] = train[target]\n",
    "train_results['baseline'] = train[target].mode()[0]\n",
    "train_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe723d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction: survived = 0\n",
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline prediction: {target} = {train[target].mode()[0]}')\n",
    "print(f'Baseline accuracy: {sk.metrics.accuracy_score(train_results.actual, train_results.baseline, normalize=True):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775fcb6",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0dbac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth = 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486fdec9",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6653bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.81\n",
      "------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       307\n",
      "           1       0.79      0.68      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.81      0.78      0.79       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "     0    1\n",
      "0  273   34\n",
      "1   61  130\n"
     ]
    }
   ],
   "source": [
    "line_break = ('-' * 30)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "# I'm not sure which represents actual vs predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e55b9e",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1861ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline  predicted\n",
       "779       1         0          1\n",
       "159       0         0          0\n",
       "738       0         0          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results['predicted'] = y_pred\n",
    "train_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff3c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t0.81\n",
      "Precision:\t\t0.79\n",
      "F1 Score:\t\t0.73\n",
      "Recall: \t\t0.68\n",
      "Support:\t\t?__?\n",
      "\n",
      "True Postive Rate:\t0.26\n",
      "False Positive Rate:\t0.07\n",
      "True Negative Rate:\t0.55\n",
      "False Negative Rate:\t0.12\n"
     ]
    }
   ],
   "source": [
    "positive = 1\n",
    "negative = 0\n",
    "n = len(train)\n",
    "\n",
    "accuracy = sk.metrics.accuracy_score(y_train, y_pred, normalize=True)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == negative)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == negative)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == positive)]) / n\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label = positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "support = '?__?' # I don't undertsand what 'support' is and how to calculate it\n",
    "\n",
    "print(f'Accuracy:\\t\\t{accuracy:.2f}')\n",
    "print(f'Precision:\\t\\t{precision:.2f}')\n",
    "print(f'F1 Score:\\t\\t{f1_score:.2f}')\n",
    "print(f'Recall: \\t\\t{recall:.2f}')\n",
    "print(f'Support:\\t\\t{support}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160d553",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274fedc",
   "metadata": {},
   "source": [
    " 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716ef5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth = 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0827e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c307c6",
   "metadata": {},
   "source": [
    " 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "385889d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.83\n",
      "------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "     0    1\n",
      "0  288   19\n",
      "1   67  124\n"
     ]
    }
   ],
   "source": [
    "line_break = ('-' * 30)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "# I'm not sure which represents actual vs predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598628a",
   "metadata": {},
   "source": [
    " 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "945cd9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t0.83\n",
      "Precision:\t\t0.87\n",
      "F1 Score:\t\t0.74\n",
      "Recall: \t\t0.65\n",
      "Support:\t\t?__?\n",
      "\n",
      "True Postive Rate:\t0.26\n",
      "False Positive Rate:\t0.07\n",
      "True Negative Rate:\t0.55\n",
      "False Negative Rate:\t0.12\n"
     ]
    }
   ],
   "source": [
    "positive = 1\n",
    "negative = 0\n",
    "n = len(train)\n",
    "\n",
    "accuracy = sk.metrics.accuracy_score(y_train, y_pred, normalize=True)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == negative)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == negative)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == positive)]) / n\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label = positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "support = '?__?' # I don't undertsand what 'support' is and how to calculate it\n",
    "\n",
    "print(f'Accuracy:\\t\\t{accuracy:.2f}')\n",
    "print(f'Precision:\\t\\t{precision:.2f}')\n",
    "print(f'F1 Score:\\t\\t{f1_score:.2f}')\n",
    "print(f'Recall: \\t\\t{recall:.2f}')\n",
    "print(f'Support:\\t\\t{support}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c394957d",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf1a8",
   "metadata": {},
   "source": [
    "The model with max depth of 4 performs better in metrics of Accuracy, Precision, and F1 Score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b914a38",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03f873",
   "metadata": {},
   "source": [
    "max_depth 3 performs better in precision\n",
    "\n",
    "max_depth 4 performs better in recall, f1 score, and accuracy\n",
    "\n",
    "(see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d06c7da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       132\n",
      "           1       0.82      0.67      0.74        82\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.82      0.79      0.80       214\n",
      "weighted avg       0.82      0.82      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with max_depth 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9edbf5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       132\n",
      "           1       0.86      0.66      0.74        82\n",
      "\n",
      "    accuracy                           0.83       214\n",
      "   macro avg       0.84      0.80      0.81       214\n",
      "weighted avg       0.83      0.83      0.82       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with max_depth 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d35357",
   "metadata": {},
   "source": [
    "# Telco Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "680c0610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "df = acquire.get_telco_data()\n",
    "df = prepare.prep_telco(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c76f013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "446aa099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t n = 3937\n",
      "test\t n = 1407\n",
      "validate n = 1688\n"
     ]
    }
   ],
   "source": [
    "train, test, validate = prepare.train_test_validate_split(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91b480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "x_validate = validate.drop(columns=target)\n",
    "y_validate = validate[target]\n",
    "\n",
    "x_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f999bef",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32200bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction: churn = No\n",
      "Baseline accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "train_results = pd.DataFrame()\n",
    "train_results['actual'] = train[target]\n",
    "train_results['baseline'] = train[target].mode()[0]\n",
    "\n",
    "print(f'Baseline prediction: {target} = {train[target].mode()[0]}')\n",
    "print(f'Baseline accuracy: {sk.metrics.accuracy_score(train_results.actual, train_results.baseline, normalize=True):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1c9df",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56087f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no max_depth established\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b427a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed7ff393",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aacf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 1.00\n",
      "------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       1.00      1.00      1.00      2891\n",
      "         Yes       1.00      0.99      1.00      1046\n",
      "\n",
      "    accuracy                           1.00      3937\n",
      "   macro avg       1.00      1.00      1.00      3937\n",
      "weighted avg       1.00      1.00      1.00      3937\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "       No   Yes\n",
      "No   2891     0\n",
      "Yes     6  1040\n"
     ]
    }
   ],
   "source": [
    "line_break = ('-' * 30)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "# I'm not sure which represents actual vs predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979b596",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3095eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t\t1.00\n",
      "Precision:\t\t1.00\n",
      "F1 Score:\t\t1.00\n",
      "Recall: \t\t0.99\n",
      "Support:\t\t?__?\n",
      "\n",
      "True Postive Rate:\t0.26\n",
      "False Positive Rate:\t0.00\n",
      "True Negative Rate:\t0.73\n",
      "False Negative Rate:\t0.00\n"
     ]
    }
   ],
   "source": [
    "positive = 'Yes'\n",
    "negative = 'No'\n",
    "n = len(train)\n",
    "\n",
    "train_results['predicted'] = y_pred\n",
    "\n",
    "accuracy = sk.metrics.accuracy_score(y_train, y_pred, normalize=True)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == negative)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == negative)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == positive)]) / n\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label = positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "support = '?__?' # I don't undertsand what 'support' is and how to calculate it\n",
    "\n",
    "print(f'Accuracy:\\t\\t{accuracy:.2f}')\n",
    "print(f'Precision:\\t\\t{precision:.2f}')\n",
    "print(f'F1 Score:\\t\\t{f1_score:.2f}')\n",
    "print(f'Recall: \\t\\t{recall:.2f}')\n",
    "print(f'Support:\\t\\t{support}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90d053",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55feb8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.80\n",
      "------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.87      0.86      0.87      2891\n",
      "         Yes       0.63      0.63      0.63      1046\n",
      "\n",
      "    accuracy                           0.80      3937\n",
      "   macro avg       0.75      0.75      0.75      3937\n",
      "weighted avg       0.80      0.80      0.80      3937\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "       No  Yes\n",
      "No   2499  392\n",
      "Yes   383  663\n",
      "------------------------------\n",
      "Accuracy:\t\t0.80\n",
      "Precision:\t\t0.63\n",
      "F1 Score:\t\t0.63\n",
      "Recall: \t\t0.63\n",
      "Support:\t\t?__?\n",
      "\n",
      "True Postive Rate:\t0.17\n",
      "False Positive Rate:\t0.10\n",
      "True Negative Rate:\t0.63\n",
      "False Negative Rate:\t0.10\n"
     ]
    }
   ],
   "source": [
    "# reestablish classifier with max_depth=4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_train)\n",
    "\n",
    "line_break = ('-' * 30)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "# I'm not sure which represents actual vs predicted\n",
    "\n",
    "positive = 'Yes'\n",
    "negative = 'No'\n",
    "n = len(train)\n",
    "\n",
    "train_results['predicted'] = y_pred\n",
    "\n",
    "accuracy = sk.metrics.accuracy_score(y_train, y_pred, normalize=True)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == negative)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == negative)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == positive)]) / n\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label = positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "support = '?__?' # I don't undertsand what 'support' is and how to calculate it\n",
    "\n",
    "print(line_break)\n",
    "print(f'Accuracy:\\t\\t{accuracy:.2f}')\n",
    "print(f'Precision:\\t\\t{precision:.2f}')\n",
    "print(f'F1 Score:\\t\\t{f1_score:.2f}')\n",
    "print(f'Recall: \\t\\t{recall:.2f}')\n",
    "print(f'Support:\\t\\t{support}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec057c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.79\n",
      "------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.93      0.87      2891\n",
      "         Yes       0.68      0.41      0.51      1046\n",
      "\n",
      "    accuracy                           0.79      3937\n",
      "   macro avg       0.75      0.67      0.69      3937\n",
      "weighted avg       0.78      0.79      0.77      3937\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "       No  Yes\n",
      "No   2691  200\n",
      "Yes   614  432\n",
      "------------------------------\n",
      "Accuracy:\t\t0.79\n",
      "Precision:\t\t0.68\n",
      "F1 Score:\t\t0.51\n",
      "Recall: \t\t0.41\n",
      "Support:\t\t?__?\n",
      "\n",
      "True Postive Rate:\t0.11\n",
      "False Positive Rate:\t0.05\n",
      "True Negative Rate:\t0.68\n",
      "False Negative Rate:\t0.16\n"
     ]
    }
   ],
   "source": [
    "# reestablish classifier with max_depth=3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_train)\n",
    "\n",
    "line_break = ('-' * 30)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "# I'm not sure which represents actual vs predicted\n",
    "\n",
    "positive = 'Yes'\n",
    "negative = 'No'\n",
    "n = len(train)\n",
    "\n",
    "train_results['predicted'] = y_pred\n",
    "\n",
    "accuracy = sk.metrics.accuracy_score(y_train, y_pred, normalize=True)\n",
    "tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == negative)]) / n\n",
    "tn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == negative)]) / n\n",
    "fn_rate = len(train_results[(train_results.predicted == negative) & (train_results.actual == positive)]) / n\n",
    "precision = sk.metrics.precision_score(y_train, y_pred, pos_label = positive)\n",
    "f1_score = sk.metrics.f1_score(y_train, y_pred, pos_label=positive)\n",
    "recall = sk.metrics.recall_score(y_train, y_pred, pos_label=positive)\n",
    "support = '?__?' # I don't undertsand what 'support' is and how to calculate it\n",
    "\n",
    "print(line_break)\n",
    "print(f'Accuracy:\\t\\t{accuracy:.2f}')\n",
    "print(f'Precision:\\t\\t{precision:.2f}')\n",
    "print(f'F1 Score:\\t\\t{f1_score:.2f}')\n",
    "print(f'Recall: \\t\\t{recall:.2f}')\n",
    "print(f'Support:\\t\\t{support}')\n",
    "print()\n",
    "print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "print(f'False Negative Rate:\\t{fn_rate:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0a522",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69720086",
   "metadata": {},
   "source": [
    "While the model with no established max-depth undoubtedly performs best, but this is likely due to overfitting.\n",
    "\n",
    "The model with max-depth 4 performs better than the one with max-depth 3 on the in-sample data (for all metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14539fd",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6b610f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.81      0.81      0.81      1239\n",
      "         Yes       0.48      0.49      0.49       449\n",
      "\n",
      "    accuracy                           0.72      1688\n",
      "   macro avg       0.65      0.65      0.65      1688\n",
      "weighted avg       0.73      0.72      0.72      1688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with no max_depth\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a04a0d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.87      0.85      1239\n",
      "         Yes       0.60      0.55      0.57       449\n",
      "\n",
      "    accuracy                           0.78      1688\n",
      "   macro avg       0.72      0.71      0.71      1688\n",
      "weighted avg       0.78      0.78      0.78      1688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with max_depth 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae60fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.80      0.93      0.86      1239\n",
      "         Yes       0.66      0.36      0.47       449\n",
      "\n",
      "    accuracy                           0.78      1688\n",
      "   macro avg       0.73      0.65      0.66      1688\n",
      "weighted avg       0.76      0.78      0.76      1688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with max_depth 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033c9cf",
   "metadata": {},
   "source": [
    "#### Results: \n",
    "for out-of-sample data, max-depth of 3 performs best for precision, recall, and f1 score. Max-depth 3 and max-depth 4 have approximately equal accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d15327",
   "metadata": {},
   "source": [
    "# OTHER DATA: Austin Animal Center Decision Tree\n",
    "### Work through these exercises on other datasets with a higher number of output classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e2a67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intakes = pd.read_csv('aac_intakes_20220304.csv')\n",
    "outcomes = pd.read_csv('aac_outcomes_20220304.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "541bafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.aac_prep(intakes, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38befd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.aac_get_dogs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb5b1d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_id</th>\n",
       "      <th>name</th>\n",
       "      <th>datetime_intake</th>\n",
       "      <th>found_location</th>\n",
       "      <th>intake_type</th>\n",
       "      <th>intake_condition</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>month_intake</th>\n",
       "      <th>fixed</th>\n",
       "      <th>sex</th>\n",
       "      <th>breed_mixed</th>\n",
       "      <th>breed_1</th>\n",
       "      <th>breed_2</th>\n",
       "      <th>breed_3</th>\n",
       "      <th>color_1</th>\n",
       "      <th>color_2</th>\n",
       "      <th>age_intake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A786884</td>\n",
       "      <td>*Brock</td>\n",
       "      <td>2019-01-03 16:19:00</td>\n",
       "      <td>2501 Magin Meadow Dr in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>January</td>\n",
       "      <td>True</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>Beagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tricolor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A706918</td>\n",
       "      <td>Belle</td>\n",
       "      <td>2015-07-05 12:59:00</td>\n",
       "      <td>9409 Bluegrass Dr in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>July</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>English Springer Spaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Liver</td>\n",
       "      <td>2920 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A724273</td>\n",
       "      <td>Runster</td>\n",
       "      <td>2016-04-14 18:43:00</td>\n",
       "      <td>2818 Palomino Trail in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>April</td>\n",
       "      <td>False</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>Basenji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sable</td>\n",
       "      <td>White</td>\n",
       "      <td>330 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal_id     name     datetime_intake                       found_location  \\\n",
       "0   A786884   *Brock 2019-01-03 16:19:00  2501 Magin Meadow Dr in Austin (TX)   \n",
       "1   A706918    Belle 2015-07-05 12:59:00     9409 Bluegrass Dr in Austin (TX)   \n",
       "2   A724273  Runster 2016-04-14 18:43:00   2818 Palomino Trail in Austin (TX)   \n",
       "\n",
       "  intake_type intake_condition animal_type     outcome_type month_intake  \\\n",
       "0       Stray           Normal         Dog         Transfer      January   \n",
       "1       Stray           Normal         Dog  Return to Owner         July   \n",
       "2       Stray           Normal         Dog  Return to Owner        April   \n",
       "\n",
       "   fixed     sex  breed_mixed                   breed_1 breed_2 breed_3  \\\n",
       "0   True    male         True                    Beagle     NaN     NaN   \n",
       "1   True  female        False  English Springer Spaniel     NaN     NaN   \n",
       "2  False    male         True                   Basenji     NaN     NaN   \n",
       "\n",
       "    color_1 color_2 age_intake  \n",
       "0  Tricolor     NaN   730 days  \n",
       "1     White   Liver  2920 days  \n",
       "2     Sable   White   330 days  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89b8a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.aac_prep_for_modeling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cab4d218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome_type</th>\n",
       "      <th>age_intake</th>\n",
       "      <th>fixed_True</th>\n",
       "      <th>fixed_unknown</th>\n",
       "      <th>breed_mixed_True</th>\n",
       "      <th>intake_type_Euthanasia Request</th>\n",
       "      <th>intake_type_Owner Surrender</th>\n",
       "      <th>intake_type_Public Assist</th>\n",
       "      <th>intake_type_Stray</th>\n",
       "      <th>intake_type_Wildlife</th>\n",
       "      <th>intake_condition_Behavior</th>\n",
       "      <th>intake_condition_Feral</th>\n",
       "      <th>intake_condition_Injured</th>\n",
       "      <th>intake_condition_Med Attn</th>\n",
       "      <th>intake_condition_Medical</th>\n",
       "      <th>intake_condition_Neonatal</th>\n",
       "      <th>intake_condition_Normal</th>\n",
       "      <th>intake_condition_Nursing</th>\n",
       "      <th>intake_condition_Other</th>\n",
       "      <th>intake_condition_Pregnant</th>\n",
       "      <th>intake_condition_Sick</th>\n",
       "      <th>month_intake_August</th>\n",
       "      <th>month_intake_December</th>\n",
       "      <th>month_intake_February</th>\n",
       "      <th>month_intake_January</th>\n",
       "      <th>...</th>\n",
       "      <th>color_1_Blue Tiger</th>\n",
       "      <th>color_1_Brown</th>\n",
       "      <th>color_1_Brown Brindle</th>\n",
       "      <th>color_1_Brown Merle</th>\n",
       "      <th>color_1_Brown Tiger</th>\n",
       "      <th>color_1_Buff</th>\n",
       "      <th>color_1_Chocolate</th>\n",
       "      <th>color_1_Cream</th>\n",
       "      <th>color_1_Fawn</th>\n",
       "      <th>color_1_Gold</th>\n",
       "      <th>color_1_Gray</th>\n",
       "      <th>color_1_Liver</th>\n",
       "      <th>color_1_Liver Tick</th>\n",
       "      <th>color_1_Orange</th>\n",
       "      <th>color_1_Red</th>\n",
       "      <th>color_1_Red Merle</th>\n",
       "      <th>color_1_Red Tick</th>\n",
       "      <th>color_1_Ruddy</th>\n",
       "      <th>color_1_Sable</th>\n",
       "      <th>color_1_Silver</th>\n",
       "      <th>color_1_Tan</th>\n",
       "      <th>color_1_Tricolor</th>\n",
       "      <th>color_1_White</th>\n",
       "      <th>color_1_Yellow</th>\n",
       "      <th>color_1_Yellow Brindle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transfer</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>2920.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Return to Owner</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      outcome_type  age_intake  fixed_True  fixed_unknown  breed_mixed_True  \\\n",
       "0         Transfer       730.0           1              0                 1   \n",
       "1  Return to Owner      2920.0           1              0                 0   \n",
       "2  Return to Owner       330.0           0              0                 1   \n",
       "\n",
       "   intake_type_Euthanasia Request  intake_type_Owner Surrender  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "\n",
       "   intake_type_Public Assist  intake_type_Stray  intake_type_Wildlife  \\\n",
       "0                          0                  1                     0   \n",
       "1                          0                  1                     0   \n",
       "2                          0                  1                     0   \n",
       "\n",
       "   intake_condition_Behavior  intake_condition_Feral  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "\n",
       "   intake_condition_Injured  intake_condition_Med Attn  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "\n",
       "   intake_condition_Medical  intake_condition_Neonatal  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "\n",
       "   intake_condition_Normal  intake_condition_Nursing  intake_condition_Other  \\\n",
       "0                        1                         0                       0   \n",
       "1                        1                         0                       0   \n",
       "2                        1                         0                       0   \n",
       "\n",
       "   intake_condition_Pregnant  intake_condition_Sick  month_intake_August  \\\n",
       "0                          0                      0                    0   \n",
       "1                          0                      0                    0   \n",
       "2                          0                      0                    0   \n",
       "\n",
       "   month_intake_December  month_intake_February  month_intake_January  ...  \\\n",
       "0                      0                      0                     1  ...   \n",
       "1                      0                      0                     0  ...   \n",
       "2                      0                      0                     0  ...   \n",
       "\n",
       "   color_1_Blue Tiger  color_1_Brown  color_1_Brown Brindle  \\\n",
       "0                   0              0                      0   \n",
       "1                   0              0                      0   \n",
       "2                   0              0                      0   \n",
       "\n",
       "   color_1_Brown Merle  color_1_Brown Tiger  color_1_Buff  color_1_Chocolate  \\\n",
       "0                    0                    0             0                  0   \n",
       "1                    0                    0             0                  0   \n",
       "2                    0                    0             0                  0   \n",
       "\n",
       "   color_1_Cream  color_1_Fawn  color_1_Gold  color_1_Gray  color_1_Liver  \\\n",
       "0              0             0             0             0              0   \n",
       "1              0             0             0             0              0   \n",
       "2              0             0             0             0              0   \n",
       "\n",
       "   color_1_Liver Tick  color_1_Orange  color_1_Red  color_1_Red Merle  \\\n",
       "0                   0               0            0                  0   \n",
       "1                   0               0            0                  0   \n",
       "2                   0               0            0                  0   \n",
       "\n",
       "   color_1_Red Tick  color_1_Ruddy  color_1_Sable  color_1_Silver  \\\n",
       "0                 0              0              0               0   \n",
       "1                 0              0              0               0   \n",
       "2                 0              0              1               0   \n",
       "\n",
       "   color_1_Tan  color_1_Tricolor  color_1_White  color_1_Yellow  \\\n",
       "0            0                 1              0               0   \n",
       "1            0                 0              1               0   \n",
       "2            0                 0              0               0   \n",
       "\n",
       "   color_1_Yellow Brindle  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "\n",
       "[3 rows x 271 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fdc0b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t n = 29929\n",
      "test\t n = 10690\n",
      "validate n = 12827\n"
     ]
    }
   ],
   "source": [
    "target = 'outcome_type'\n",
    "train, test, validate = prepare.train_test_validate_split(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "829c1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "x_validate = validate.drop(columns=target)\n",
    "y_validate = validate[target]\n",
    "\n",
    "x_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316f54d",
   "metadata": {},
   "source": [
    "#### 1. What is your baseline prediction? What is your baseline accuracy? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d13e52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction: outcome_type = Adoption\n",
      "Baseline accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "train_results = pd.DataFrame()\n",
    "train_results['actual'] = train[target]\n",
    "train_results['baseline'] = train[target].mode()[0]\n",
    "print(f'Baseline prediction: {target} = {train[target].mode()[0]}')\n",
    "print(f'Baseline accuracy: {sk.metrics.accuracy_score(train_results.actual, train_results.baseline, normalize=True):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29694408",
   "metadata": {},
   "source": [
    "#### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430ed0c",
   "metadata": {},
   "source": [
    "#### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a35fa1",
   "metadata": {},
   "source": [
    "#### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99976e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.58\n",
      "------------------------------\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.58      0.82      0.68     14433\n",
      "Return to Owner       0.61      0.60      0.61      7272\n",
      "       Transfer       0.52      0.15      0.24      8224\n",
      "\n",
      "       accuracy                           0.58     29929\n",
      "      macro avg       0.57      0.52      0.51     29929\n",
      "   weighted avg       0.57      0.58      0.54     29929\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "                 Adoption  Return to Owner  Transfer\n",
      "Adoption            11805             1665       963\n",
      "Return to Owner      2727             4358       187\n",
      "Transfer             5906             1068      1250\n",
      "------------------------------\n",
      "For outcome_type == Transfer:\n",
      "\n",
      "True Postive Rate:\t0.04\n",
      "False Positive Rate:\t0.04\n",
      "True Negative Rate:\t0.69\n",
      "False Negative Rate:\t0.23\n",
      "------------------------------\n",
      "For outcome_type == Return to Owner:\n",
      "\n",
      "True Postive Rate:\t0.15\n",
      "False Positive Rate:\t0.09\n",
      "True Negative Rate:\t0.67\n",
      "False Negative Rate:\t0.10\n",
      "------------------------------\n",
      "For outcome_type == Adoption:\n",
      "\n",
      "True Postive Rate:\t0.39\n",
      "False Positive Rate:\t0.29\n",
      "True Negative Rate:\t0.23\n",
      "False Negative Rate:\t0.09\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "line_break = ('-' * 30)\n",
    "\n",
    "# Max-depth = 3\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "print(line_break)\n",
    "# I'm not sure which represents actual vs predicted\n",
    "\n",
    "\n",
    "for outcome_type in df.outcome_type.unique():\n",
    "    \n",
    "    print(f'For outcome_type == {outcome_type}:')\n",
    "    positive = outcome_type\n",
    "    n = len(train)\n",
    "\n",
    "    train_results['predicted'] = y_pred\n",
    "\n",
    "    tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "    fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual != positive)]) / n\n",
    "    tn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual != positive)]) / n\n",
    "    fn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual == positive)]) / n\n",
    "    \n",
    "    print()\n",
    "    print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "    print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "    print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "    print(f'False Negative Rate:\\t{fn_rate:.2f}')\n",
    "    print(line_break)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9aea18",
   "metadata": {},
   "source": [
    "#### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d42276b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.59\n",
      "------------------------------\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.57      0.85      0.68     14433\n",
      "Return to Owner       0.62      0.59      0.60      7272\n",
      "       Transfer       0.60      0.12      0.20      8224\n",
      "\n",
      "       accuracy                           0.59     29929\n",
      "      macro avg       0.60      0.52      0.50     29929\n",
      "   weighted avg       0.59      0.59      0.53     29929\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      "                 Adoption  Return to Owner  Transfer\n",
      "Adoption            12244             1656       533\n",
      "Return to Owner      2836             4302       134\n",
      "Transfer             6236              998       990\n",
      "------------------------------\n",
      "For outcome_type == Transfer:\n",
      "\n",
      "True Postive Rate:\t0.03\n",
      "False Positive Rate:\t0.02\n",
      "True Negative Rate:\t0.70\n",
      "False Negative Rate:\t0.24\n",
      "------------------------------\n",
      "For outcome_type == Return to Owner:\n",
      "\n",
      "True Postive Rate:\t0.14\n",
      "False Positive Rate:\t0.09\n",
      "True Negative Rate:\t0.67\n",
      "False Negative Rate:\t0.10\n",
      "------------------------------\n",
      "For outcome_type == Adoption:\n",
      "\n",
      "True Postive Rate:\t0.41\n",
      "False Positive Rate:\t0.30\n",
      "True Negative Rate:\t0.21\n",
      "False Negative Rate:\t0.07\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "line_break = ('-' * 30)\n",
    "\n",
    "# Max-depth = 4\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_train)\n",
    "\n",
    "print(f'Model Score: {clf.score(x_train, y_train):.2f}')\n",
    "print(line_break)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(line_break)\n",
    "labels = sorted(y_train.unique())\n",
    "print('Confusion Matrix:')\n",
    "print(pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels))\n",
    "print(line_break)\n",
    "# I'm not sure which represents actual vs predicted\n",
    "\n",
    "\n",
    "for outcome_type in df.outcome_type.unique():\n",
    "    \n",
    "    print(f'For outcome_type == {outcome_type}:')\n",
    "    positive = outcome_type\n",
    "    n = len(train)\n",
    "\n",
    "    train_results['predicted'] = y_pred\n",
    "\n",
    "    tp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual == positive)]) / n\n",
    "    fp_rate = len(train_results[(train_results.predicted == positive) & (train_results.actual != positive)]) / n\n",
    "    tn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual != positive)]) / n\n",
    "    fn_rate = len(train_results[(train_results.predicted != positive) & (train_results.actual == positive)]) / n\n",
    "    \n",
    "    print()\n",
    "    print(f'True Postive Rate:\\t{tp_rate:.2f}')\n",
    "    print(f'False Positive Rate:\\t{fp_rate:.2f}')\n",
    "    print(f'True Negative Rate:\\t{tn_rate:.2f}')\n",
    "    print(f'False Negative Rate:\\t{fn_rate:.2f}')\n",
    "    print(line_break)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9dc277",
   "metadata": {},
   "source": [
    "#### 6. Which model performs better on your in-sample data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5c523fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max-Depth = 3\n",
    "    # Classification Report:\n",
    "    #                 precision    recall  f1-score   support\n",
    "\n",
    "    #       Adoption       0.58      0.82      0.68     14433\n",
    "    # Return to Owner      0.61      0.60      0.61      7272\n",
    "    #       Transfer       0.52      0.15      0.24      8224\n",
    "\n",
    "    #       accuracy                           0.58     29929\n",
    "    \n",
    "# Max-Depth = 4\n",
    "# Classification Report:\n",
    "#                  precision    recall  f1-score   support\n",
    "\n",
    "#        Adoption       0.57      0.85      0.68     14433\n",
    "# Return to Owner       0.62      0.59      0.60      7272\n",
    "#        Transfer       0.60      0.12      0.20      8224\n",
    "\n",
    "#        accuracy                           0.59     29929"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8babf5cf",
   "metadata": {},
   "source": [
    "There are only very slight differences in accuracy, precision, and recall between the two models (can be seen above) and which one is \"better\" would depend on what the goals of the model's predictions are and which outcome_type category we are trying to identify as our positive case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e59b4",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on your out-of-sample data, the validate set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c64c5532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max-Depth = 3:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.58      0.82      0.68      6185\n",
      "Return to Owner       0.62      0.61      0.61      3117\n",
      "       Transfer       0.53      0.15      0.24      3525\n",
      "\n",
      "       accuracy                           0.59     12827\n",
      "      macro avg       0.57      0.53      0.51     12827\n",
      "   weighted avg       0.57      0.59      0.54     12827\n",
      "\n",
      "------------------------------\n",
      "Max-Depth = 4\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.58      0.85      0.69      6185\n",
      "Return to Owner       0.62      0.60      0.61      3117\n",
      "       Transfer       0.59      0.13      0.21      3525\n",
      "\n",
      "       accuracy                           0.59     12827\n",
      "      macro avg       0.60      0.52      0.50     12827\n",
      "   weighted avg       0.59      0.59      0.54     12827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-establish classifier with max-depth = 3\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print('Max-Depth = 3:')\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# re-establish classifier with max_depth = 4\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "# create predictions for the validate set\n",
    "y_pred = clf.predict(x_validate)\n",
    "\n",
    "# display report\n",
    "print(line_break)\n",
    "print('Max-Depth = 4')\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e72f5",
   "metadata": {},
   "source": [
    "Again, there are only very slight differences in accuracy, precision, and recall between the two models (can be seen above) and which one is \"better\" would depend on what the goals of the model's predictions are and which outcome_type category we are trying to identify as our positive case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
